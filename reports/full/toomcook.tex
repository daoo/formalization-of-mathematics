\subsection{Toom-Cook}
Toom-Cook är en algoritm för att multiplicera två polynom och är namngiven
efter Andrei Toom och Stephen Cook.

Algoritmen är intressant eftersom den har en bättre asymptotisk tidskomplexitet
än naiv polynommultiplikation där man multiplicerar varje term i det ena
polynomet med varje term i det andra polynomet vilket har den asymptotiska
tidskomplexiteten $O\left(n^2\right)$. Eftersom problemet att multiplicera två
heltal kan reduceras till att multiplicera två polynom kan algoritmen även
användas för heltalsmultiplikation, denna reduktion kan göras utan att den
asymptotiska tidskomplexiteten försämras. Detta innebär att man kan uppnå en
bättre asymptotisk tidskomplexitet än den för naiv heltalsmultiplikation som
lärs ut i grundskolan och har den asymptotiska tidskomplexiteten
$O\left(n^2\right)$.

Toom-Cook är en $"$divide and conquer$"$-algoritm och bygger på att man delar
upp polynomen som skall multipliceras i mindre delar, dessa delar får sedan stå
som koefficienter i två nya polynom som evalueras i olika punkter för att sedan
punktvis multipliceras och därefter interpoleras tillbaka till ett nytt
polynom. Genom att evaluera det nya polynomet i en punkt som svarar mot hur
stora delar de ursprungliga polynomen delades upp i så får man slutligen
produkten. Detta är dock bara de ingående stegen, för en mer detaljerad
beskrivning av algoritmen se följande undersektion.

Det finns flera varianter
av Toom-Cook. Toom-k är en enskild instans av Toom-Cook som delar polynomen som
skall multipliceras i k delar. Vanligtvis när man talar om Toom-Cook syftar man
på Toom-3. Det finns även Toom-versioner som delar upp polynomen i olika antal
delar. Två intressanta specialfall av Toom-Cook är Toom-1 som svarar mot naiv
polynommultiplikation och Toom-2, Karatsuba-algoritmen. Toom-k har den
asymptotiska tidskomplexiteten $O(n^{log_2(2 k-1)/log_2 k})$, men konstanten
som döljs av ordo-notationen växer med k och har en betydande praktisk
inverkan. För heltalsmultiplikation finns algoritmer som bygger på diskret
fouriertransform och har en ännu bättre asymptotisk tidskomplexitet, t ex
Schönhage-Strassen-algoritmen.

Både Toom-Cook och algoritmer som bygger på diskret fouriertransform används i
praktiken. I t ex gmplib, The GNU Multiple Precision Arithmetic Library,
används Schönhage-Strassen-algoritmen samt olika instanser av
Toom-Cook-algoritmen för multiplikation av heltal.

\subsubsection{Definition av Toom-Cook-$m$}
I detta avsnitt definierar vi Toom-Cook m $(p, q)$, för $m \in \mathbb{N}$ och
$m \geq 3$, som resultatet av algoritmen nedan. Versionen av algoritmen som
presenteras nedan bygger på \cite{bodrato2007a} och presentationen av den
följer källans. För en introduktion till integritetsområden och polynom, se
APPENDIX NÅNTING.

Låt R vara ett integritetsområde och låt $p, q \in R[x]$, där
\begin{align*}
  &p(x) = a_0 + a_1 x + ... + a_n x^n, \\
  &q(x) = b_0 + b_1 x + ... + b_s x^s
\end{align*}
med $0 \leq s \leq n$.

\paragraph{Gradkontroll}
Om $\grad p = n \leq 2$, låt Toom-Cook $m (p, q) = p \cdot q$, annars gå vidare
till steg 2.

\paragraph{Uppdelning}
\label{uppdelning}
Låt
\begin{align*}
  b&=\displaystyle \lfloor \frac{1 + \grad p}{m}\rfloor + 1 = \lfloor \frac{1 + n}{m}\rfloor + 1.
\intertext{För $f \in R[x]$ och}
  f &= q x^k + r
\intertext{med $q, r \in R[x]$ och $r = 0$ eller $\grad r \leq \grad x^k$, låt}
  f/x^k &= q \\
  f \modu x^k &= r.
\intertext{Nu definierar vi $u, v \in R[x][y]$. Låt}
  u(y)&=u_0 + u_1 y + ... + u_{m-1} y^{m-1}
\intertext{där}
  u_k &= p / x^{bk} \modu x^b
\intertext{och}
  v(y)&=v_0 + v_1 y + ... + v_{m-1} y^{m-1}
\intertext{där}
  v_k &= q / x^{bk} \modu x^b
\end{align*}
Vi vill att $u(x^b)=p(x)$ och $v(x^b)=q(x)$.

\paragraph{Evaluering}
Nu ska vi beräkna $w = u \cdot v$. Vi gör detta genom interpolation. Vi
beräknar $w(\alpha_i)=u(\alpha_i) \cdot v(\alpha_i)$ för $d + 1$ punkter
$\alpha_0, ...,  \alpha_d$, där $\alpha_i \in R$ och

\begin{align*}
  d = m - 1 + m -1 = 2m-2 \geq \grad w = \grad u + \grad v.
\end{align*}
Därefter bestäms koefficienterna i $w$ genom interpolation. I detta steg
beräknar vi $u(\alpha_i)$ och $v(\alpha_i)$. Låt
\begin{align*}
  V_e &=
  \begin{pmatrix}
    \alpha_0^0 & \alpha_0^1 & ... & \alpha_0^{m-1} \\
    \vdots     & \vdots     &     & \vdots         \\
    \alpha_d^0 & \alpha_d^1 & ... & \alpha_d^{m-1}
  \end{pmatrix}.
\intertext{Då får vi}
  V_e \cdot
  \begin{pmatrix}
    u_0    \\
    \vdots \\
    u_{m-1}
  \end{pmatrix}
  &=
  \begin{pmatrix}
    u(\alpha_0) \\
    \vdots      \\
    u(\alpha_d)
  \end{pmatrix}
\end{align*}
och motsvarande för $v$.

\paragraph{Rekursiv multiplikation}
Vi beräknar $w(\alpha_i)=u(\alpha_i) \cdot v(\alpha_i)$ för i $= 0, ... , d$
rekursivt genom att anropa algoritmen med $u(\alpha_i)$ och $v(\alpha_i)$ som
argument. Notera att $u(\alpha_i)$, $v(\alpha_i) \in R[x]$.

\paragraph{Interpolation}
Vi bestämmer koefficienterna i $w(y)=w_0 + w_1 y + \ldots + w_d y^d$ genom
interpolation. Om

\begin{align}
  \label{eq:NAME3}
  V_I &=
  \begin{pmatrix}
    \alpha_0^0 & \alpha_0^1 & ... & \alpha_0^d \\
    \vdots     & \vdots     &     & \vdots     \\
    \alpha_d^0 & \alpha_d^1 & ... & \alpha_d^d
  \end{pmatrix}
\intertext{så är}
  \label{eq:NAME4}
  V_I \cdot
  \begin{pmatrix}
    w_0    \\
    \vdots \\
    w_d
  \end{pmatrix}
  &=
  \begin{pmatrix}
    w(\alpha_0) \\
    \vdots      \\
    w(\alpha_d)
  \end{pmatrix}
\intertext{och därmed är}
  \label{eq:NAME5}
  \begin{pmatrix}
    w_0    \\
    \vdots \\
    w_d
  \end{pmatrix} &=
  V_I^{-1} \cdot
  \begin{pmatrix}
    w(\alpha_0) \\
    \vdots      \\
    w(\alpha_d)
  \end{pmatrix}
\intertext{förutsatt att $V_I$ är inverterbar. Detta är den om $\det V_I$ är
ett invertarbart elemet i $R$ [referens]. Eftersom $V_I$ är en
Vandermondematris så är}
  \label{eq:NAME6}
  \det V_I &= \prod_{0 \leq i < j \leq d} (\alpha_i - \alpha_j)
\end{align}

\paragraph{Sammansättning}
Vi får slutligen det önskade resultatet $p(x) \cdot q(x)$ genom att evaluera
$w$ i $x^b$.

\subsubsection{Bevis av algoritmens korrekthet}
I detta stycke visar vi att för $p, q \in R[x]$ så är $p \cdot q =$ Toom-Cook m
$(p, q)$.

\begin{proposition}
  \label{prop:1}
  Antag att $R$ är ett integritetsområde och att $p, q \in R[x]$. Om det finns
  $\alpha_0, ...,  \alpha_{2m-2} \in R$ så att $ \prod_{0 \leq i < j \leq d}
  (\alpha_i - \alpha_j)$ är inverterbar i $R$, så är med dessa punkter som
  evalueringspunkter

  \begin{equation}
    \label{eq:name7}
    \text{Toom-Cook m} (p, q) =  p \cdot q.
  \end{equation}
\end{proposition}

\begin{proof}
Vi visar propositionen med induktion över $\grad p$.

\noindent\textbf{Basfall}. När $n = \grad p \leq 2$ så gäller (\ref{eq:name7})
enligt steg 1 i algoritmen eftersom att vi räknar ut produkt direkt.

\bigskip\noindent
\textbf{Induktionssteg}. Antag att $p, q \in R[x]$, där
\begin{align*}
  &p(x) = a_0 + a_1 x + ... + a_n x^n, \\
  &q(x) = b_0 + b_1 x + ... + b_s x^s
\end{align*}
med $0 \leq s \leq n$.

\bigskip\noindent
Antag också att $n > 2$ och att Toom-Cook $m (f, g) =  f \cdot g$ gäller för
polynom av grad mindre än $n$. Eftersom $n > 2$ så går vi vidare till steg 2 i
algoritmen och skapar $u$ och $v$ från $p$ och $q$. När detta är gjort
evaluerar vi i steg 3 $u$ och $v$ i punkterna $\alpha_0, ...,  \alpha_{2m-2}$
genom att multiplicera vektorn av deras koefficienter med evalueringsmatrisen.
I steg 4 anropar vi Toom-Cook m  igen, nu med argumenten $u(\alpha_i) \cdot
v(\alpha_i)$ för $i = 0, \ldots , 2m-2$. Eftersom $\grad u(\alpha_i)$, $\grad
v(\alpha_i) < n$ enligt lemma \ref{lemma:1} så är Toom-Cook m $(u(\alpha_i),
v(\alpha_i)) = u(\alpha_i) \cdot v(\alpha_i)$ enligt induktionsantagnandet. I
steg 5 skall vi bestämma koefficienterna i $w(y)=u(y) \cdot v(y)$. Detta gör vi
genom att lösa matrisekvationen (\ref{eq:NAME4}). Eftersom
interpolationsmatrisen $V_I$ enligt antagande är inverterbar så ges
koefficienterna entydigt av (\ref{eq:NAME5}). I steg 6 evaluerar vi $w(y)=u(y)
\cdot v(y)$ i $x^b$. Lemma \ref{lemma:2} ger att $u(x^b)=p(x)$ och att
$v(x^b)=q(x)$. Då $w(y)=u(y) \cdot v(y)$ så är $w(x^b)=u(x^b) \cdot v(x^b)=p(x)
\cdot q(x)$.
\end{proof}

\begin{lemma}
  \label{lemma:1}
  Antag att $p(x) \in R[x]$ och att $\grad p \geq 3$. Antag också att $u(y)$ är
  definierad enligt steg \ref{uppdelning}, uppdelning, i algoritmen och att
  $\alpha \in R$. Då är $\grad u(\alpha) < \grad p$.
\end{lemma}
\begin{proof}
  Eftersom $\alpha \in R$ så är
  \begin{align*}
    \grad u(\alpha) &= \grad (u_0 + u_1 \alpha + ... + u_{m-1}\alpha^{m-1}) = \max \grad u_k,
  \end{align*}
  där $k={0,1,...,m-1}$.

  \bigskip\noindent
  $u_k = p(x)/x^{k b} \modu x^b$, så enligt definition av mod så är $\grad u_k
  < b$. Nu återstår att visa att $b < \grad p = n$. Vi har definierat $b =
  \lfloor \frac{1 + n}{m}\rfloor + 1$. Om $n \geq 3$ och $m \geq 3$ så är
  \begin{align*}
    n-b &= n-(\lfloor \frac{1 + n}{m}\rfloor + 1) \geq \frac{2n-4}{3} > 0,
  \end{align*}
  så $b < \grad p(x) = n$.
\end{proof}

\begin{lemma}
  \label{lemma:2}
  Antag att $p(x) \in R[x]$ och att $b$ och $u(y)$ är definierade som i steg 2 i
  algoritmen. Då är $u(x^b)=p(x)$.
\end{lemma}
\begin{proof}
  Vi har att
  \begin{align*}
    u(x^b) &= \sum_{i = 0}^{m-1} p(x)/x^{bi} (\modu x^b) x^{bi} \\
           &= \sum_{i = 0}^{m-2} p(x)/x^{bi} (\modu x^b) x^{bi} + p(x)/x^{b(m-1)} (\modu x^b) x^{b (m-1)}.
  \end{align*}
  \bigskip\noindent
  \textbf{Påstående 1.} Den sista termen i $u(x^b)$ kan skrivas om till
  $p(x)/x^{b (m-1)} x^{b (m-1)}$ eftersom $\grad p - b (m-1) < b$.

  Med $\grad p = n$ har vi att
  \begin{align*}
    b - (n - b(m-1)) &= m b - n \\
                     &= m (\lfloor \frac{1 + n}{m}\rfloor + 1) - n \\
                     &= m( \frac{1 + n}{m} -\{ \frac{1 + n}{m}\} ) + m - n \\
                     &= 1 + n - m \{ \frac{1 + n}{m}\} + m - n \\
                     &= 1 + m(1 - \{ \frac{1 + n}{m}\}) > 0
  \end{align*}
  eftersom $0 < 1 - \{ x \} \leq 1$ för alla reella tal $x$ \footnote{$\{x\}$
  betecknar $x-\lfloor x \rfloor$. Se \cite{concrete}.}. Graden av
  $p(x)/x^{b(m-1)}$ är $\max (n - b(m-1),0)$ som är mindre än $b$, och därmed är
  $p(x)/x^{b(m-1)}  \modu x^b = p(x)/x^{b(m-1)}$, vilket visar Påstående 1. Så
  \begin{align*}
    u(x^b) &= \sum_{i = 0}^{m-2} p(x)/x^{bi} (\modu x^b) x^{bi} + p(x)/x^{b(m-1)} x^{b(m-1)}.
  \end{align*}
  För alla polynom $a(x)$ gäller att
  \begin{align}
    a(x) = a(x) \modu x^b + \left(a(x)/x^b\right) x^b \label{eq:name8}
  \end{align}
  då $a(x) \modu x^b$ och $p(x)/x^{b}$ är resten respektive kvoten vid division
  med $x^b$. Så om vi kan visa att $u(x^b) =  p(x) \modu x^b + p(x)/x^{b}  x^{b}$
  så är $u(x^b) = p(x)$. Och om sedan
  \begin{align}
    \sum_{i = 0}^{k} p(x)/x^{bi}  (\modu x^b) x^{bi} + (p(x)/x^{b(k + 1)})  x^{b(k + 1)} = \label{eq:name9} \\
    \sum_{i = 0}^{k-1} p(x)/x^{bi}  (\modu x^b) x^{bi} + (p(x)/x^{b k})  x^{b k} \label{eq:name10}
  \end{align}
  för $k \geq 1$ så ger induktion över $k$ att $u(x^b) =  p(x)$. Nu återstår
  alltså bara att visa att (\ref{eq:name9}) = (\ref{eq:name10}).

  \begin{align*}
    \sum_{i = 0}^{k} p(x)/x^{bi} (\modu x^b) x^{bi} &+ p(x)/x^{b(k + 1)}  x^{b(k + 1)} =\\
    \sum_{i = 0}^{k-1} p(x)/x^{bi} (\modu x^b) x^{bi} &+
    \left(p(x)/x^{b k} \modu x^b\right) x^{b k} + \left(p(x)/x^{b(k + 1)}\right)  x^{b(k + 1)} = \\
    \sum_{i = 0}^{k-1} p(x)/x^{bi} (\modu x^b) x^{bi} &+
    \left(p(x)/x^{b k} \modu x^b + \left(p(x)/x^{b(k + 1)}\right)  x^b \right) x^{b k} = \\
    \sum_{i = 0}^{k-1} p(x)/x^{bi} (\modu x^b) x^{bi} &+
    (p(x)/x^{b k} \modu x^b + ((p(x)/x^{b k})/x^b)  x^b) x^{b k} =
    \tag{på grund av (\ref{eq:name8})}\\
    \sum_{i = 0}^{k-1} p(x)/x^{bi}  (\modu x^b) x^{bi} &+ (p(x)/x^{b k}) x^{b k}
  \end{align*}
\end{proof}

\subsubsection{Karatsuba}
Toom-2 är ett specialfall av Toom-Cook och är även känd som
Karatsuba-algoritmen. I Karatsuba-algoritmen delas multiplikanderna upp på
samma sätt som i steg 1.2 i Toom-m algoritmen ovan vilket ger oss de två
polynomen:
\begin{align*}
  u(x) &= u_1 y + u_0 \\
  v(x) &= v_1 y + v_0
\end{align*}
Om vi skall multiplicera polynomen med naiv polynommultiplikation krävs det
fyra multiplikationer:
\begin{equation*}
  u_1 v_1 y^2 + (u_1 v_0+v_1 u_0) y + u_0 v_0
\end{equation*}
Genom att skriva om uttrycket krävs dock bara tre distinkta multiplikationer:
\begin{equation*}
  u_1 v_1 y^2 + ((u_1 + u_0)(v_1 + v_0) - u_1 v_1 - u_0 v_0) y + u_0 v_0
\end{equation*}
Tidskomplexiteten för Karatsuba-algoritmen är då:
\begin{equation*}
  T(n) = 3 T(\lceil n/2\rceil) + cn + d
\end{equation*}
där n är graden på det största polynomet och c och d är konstanter. Alltså har
Karatsuba-algoritmen den asymptotiska tidskomplexiteten $O(n^{log_2 3})$
